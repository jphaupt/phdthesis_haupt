\chapter{Monte Carlo Methods}
\label{chap:qmc}
\todo{...}
\todo{look especially at thijssen and the foulkes review for these sections}

% probably get some inspiration from Kai's and Werner's theses -- focus on FCIQMC

\gls{MC} methods are a class of numerical methods that use random sampling to numerically solve problems. It has found applications in an impressive range of fields, from physics to finance.\todo{citation} It is particularly useful for problems with high dimensionality, where deterministic methods are often impractical. In quantum chemistry and physics, since a `dimension' can refer to any degree of freedom, high-dimensional problems are commonplace, and so \gls{MC} methods are a natural choice.

While the name \emph{Monte Carlo} was coined by Stanislav Ulam, after the famous casino in Monaco,\todo{citation} the foundational concept was already developed in the 18th century by the French mathematician Georges-Louis Leclerc, Comte de Buffon. As one of the earliest example applications, in the Buffon needle problem, one can randomly toss needles onto a lined sheet of paper and determine $\pi$.\todo{citation}

Monte Carlo methods is a broad term, and as such it is not possible to give a comprehensive overview in a single chapter, and there exist many reviews and textbooks on \gls{MC} and related topics.\todo{citations: see those in thijssen} Here, we will focus on only a few concepts particularly relevant for this dissertation, largely following reference \citenum{foulkesQuantum} and the relevant chapters of reference \citenum{thijssenComputational2007}.

\section{Classical Monte Carlo Methods}

We start our discussion with classical \gls{MC} methods. While there are numerous possible applications, such as molecular dynamics,\todo{cite}, here we restrict ourselves to the topic of Monte Carlo integration. In particular, we consider the classical textbook problem of calculating the value of $\pi$, then we provide a more rigorous framework.

\subsection{A Very Bad Game of Darts}

If we imagine throwing darts at a dartboard randomly, we can approximate $\pi$. If the radius of the circle is $r$, then its area is $\pi r^2$. The area of the square circumscribing the circle is $4r^2$. Therefore, the ratio of the area of the circle to the area of the square is $\pi/4$. If we randomy sample a point in the square (``throw a dart''), the probability that the point is inside the circle is proportional its area. Since we sample inside the square, the probability of landing inside the circle is
\begin{equation}
    P(\text{inside circle}) =  \frac{\pi r^2}{4r^2} = \frac{\pi}{4}.
\end{equation}
Therefore, if we sample a large number of points, the ratio of the number of darts that land inside the unit circle to the total number of darts, we can approximate the probability distribution $P$ and thus get an estimate for $\pi$. This is illustrated in figure \ref{fig:darts}, and captures the core philosophy of \gls{MC} methods.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=\textwidth]{figures/qmc/darts.pdf}
    \caption{Our ``game of darts''. Points inside the unit circle are coloured blue whereas points outside are orange. Using stochastic sampling, this naive approach uses 5000 randomly generate numbers between -1 and 1 to approximate $\pi\approx 4N_\mathrm{in}/N_\mathrm{out}\approx 3.1464$. Of course, there are many ways to improve this method, the most obvious being to use a fraction of the unit circle, such as the first quadrant.}
    \label{fig:darts}
\end{figure}

\subsection{A More Mathematical Description}

As we have expressed the problem of the previous section in terms of areas, it is clear that it can also be formulated in terms of integrals. For this particular problem, we have:
\begin{equation}
    \pi = \int_{-1}^1  \mathrm{d}x \int_{-1}^1 \mathrm{d}y\ \Theta(1-x^2-y^2) ,
\end{equation}
where $\Theta$ is the Heaviside step function.
More generally, consider the integral of some smooth function $f$ over $[a,b]\subseteq \mathbb{R}$,\footnote{We present the one-dimensional case for simplicity. The generalization to higher dimensions is straightforward.}
\begin{equation}
    I = \int_a^b \d x \ f(x).
\end{equation}
Standard finite element methods for solving integrals of this type typically involving dividing the integration domain into $N$ subintervals of length $h$ and determining the weights $w_i$ from e.g. a polynomial approximation. The error $\sigma$ in these sorts of methods is typically $\sigma\propto h^{-k} \propto N^{-k}$, where $k\in\mathbb{Z}_{>0}$. For a multi-dimensional integral, $\sigma\propto N^{-k/d}$, where $d$ is the number of dimensions.\cite{ascherFirst2011}
% I am mostly following the discussion and notation in Thijssen's book -- remember to cite it along with all the primary references

In \gls{MC} methods,\todo{citations} $\forall i$ take $w_i=1$ and $x_i\in[a,b]$ randomly sampled. For uniformly sampled points, t`he variance is then
\begin{align}
    \sigma^2 &= \left\langle \left( \frac{b-a}{N}\sum^N_{i=1}f_i\right)2\right\rangle - \left( \left\langle  \frac{b-a}{N}\sum^N_{i=1}f_i\right\rangle\right)^2 \\
    &= \frac{(b-a)^2}{N}(\bar{f^2} - \bar f^2)
\end{align}
where $f_i\mathdef f(x_i)$ and $x_i$ is a random number drawn, the angular brackets denote an average over all possible realisations, and the overbar represents an average of the function over the domain ($[a,b]$ in this discussion). i.e. the error in this method is proportional to the variance of $f$. Perhaps more interestingly, $\sigma\propto N^{-1/2}$, in line with the central limit theorem.\todo{citations} Comparing this error with standard quadrature, we see that MC integration is moroe efficient than an order-$k$ algorithm when $d>2k$. That is, although this particular \gls{MC} example is naive, using simply a uniform distribution, it is still more efficient than standard methodologies for very large dimensions.

There exist several methods to reduce errors in \gls{MC} methods.\todo{citations} Among the most important ones is importance sampling. In the prevous example, it is clear that if significant contributions to the integral come from a small region of the domain, only a few points would be sampled by the \gls{MC} algorithm there. This would lead to large statistical errors. Mathematically, this is from the large variance of the function. In importance sampling, we sample from a distribution $p$ which has roughly the same shape as $f$ such that $f/p$ is roughly constant over the integration domain. Of course, being a probability distribution, we require
\begin{equation}
    p(x)>0 \quad \forall x
\end{equation}
and
\begin{equation}
    \int\d x \ p(x) = 1.
\end{equation}

The integral is
\begin{equation}
    I = \int\d x \  f(x) = \int\d x\ \frac{f(x)}{p(x)} p(x).
\end{equation}
Then, if we sample points according to $p$, we have
\begin{equation}
    I\approx \frac{1}{N}\sum^N_{i=1} \frac{f(x_i)}{p(x_i)},
\end{equation}
where the naive \gls{MC} method is recovered when $p(x)=1/(b-a)$, i.e. the uniform distribution.

In this case, the variance in the result is
\begin{equation}
    \sigma^2 = \left\langle \left( \frac{1}{N}\sum^N_{i=1} \frac{f(x_i)}{p(x_i)}\right)^2\right\rangle - \left( \left\langle  \frac{1}{N}\sum^N_{i=1} \frac{f(x_i)}{p(x_i)}\right\rangle\right)^2.
\end{equation}
From this, we can see that if $f/p$ is constant, the error vanishes, so it is important to choose a good $p$. If $p$ is chosen poorly, the variance can be worsened, so this is a delicate problem.

In practice it is often difficult to estimate $f$, and a choice for $p$ is problem-specific. However, when we have some approximation for its overall shape, importance sampling can be a powerful tool. Alternatively, another method known as adaptive Monte Carlo\todo{citation} seeks the most significant regions of $f$ by random sampling, so that no a priori knowledge of the functional form is required.

\subsection{Metropolis-Hastings Algorithm}
\label{sec:mcmc}
A particularly successful method for generating random samples $x_i$ from a probability distribution $\pi(x)$, where direct sampling of $\pi$ is difficult, is the Metropolis-Hastings algorithm.\todo{citation} Often, $\pi(x)$ is known only up to a normalisation constant, $\pi(x)=\pi(x)/C$ where $C=\int\d x\ \pi(x)$ is intractible.

The Metropolis-Hastings algorithm is based on Markov chains\todo{cite}, and we construct such a Markov chain so that its stationary distribution is $\pi(x)$, which is to say if the Markov chain starts at $\pi(x)$ for step $t$, it is still $\pi(x)$ for step $t+1$.

The probability of having a sequence of states $x_1,x_2,\ldots,x_N$ is
\begin{equation}
    p(x_1,x_2,\ldots,x_N) = p(x_1)p(x_2|x_1)p(x_3|x_2)\cdots p(x_N|x_{N-1}).
\end{equation}
where $p(x|x')$ is the transition probability from $x'\to x$. Then, the probability at step $t$ to be in state $x$, $\pi_t(x)$ is given by
\begin{equation}
\pi_{t+1}(x) = \sum_{x'\in \Omega} \pi_t(x')p(x|x')
\end{equation}
where $\Omega$ is the set of all possible states. This is called the master equation. In the stationary state, $\pi_t(x)=\pi(x)$, so
\begin{equation}
    \pi(x) = \sum_{x'\in \Omega} \pi(x')p(x|x').
\end{equation}
Finding the general solution to this problem is nontrivial. However, a sufficient (but not necessary) condition is called detailed balance:
\begin{equation}
    \pi(x)p(x|x') = \pi(x')p(x'|x).
\end{equation}
This ensures that the probability of going from $x$ to $x'$ is the same as the probability of going from $x'$ to $x$, which implies that the probability is stationary.

In order to actually construct the algorithm, we must introduce the trial step probability $\omega(x|x')$, and the acceptance probability $A(x|x')$. Then,
\begin{equation}
    p(x|x') = \omega(x|x')A(x|x').
\end{equation}
$\omega(x|x'),A(x|x')\in [0,1]$ for each pair $x,x'$, and $\sum_{x'}\omega(x|x') = 1$. Furthermore, the original formulation of the algorithm required $\omega(x|x') = \omega(x'|x)$, which leads to (plugging into the master equation)
\begin{equation}
    \frac{A(x|x')}{A(x'|x)} = \frac{\pi(x')}{\pi(x)}.
\end{equation}

The algorithm proceeds in two stages: we propose a step $x'\to x$, and then accept or reject it. The probability of accepting is
\begin{equation}
    A(x|x') = \min\left(1,\frac{\pi(x')}{\pi(x)}\right).
\end{equation}
If we accept, we set the new state to $x$, otherwise we stay at $x'$.

In practice, on a computer, accepting is done by generating a random number $r\in [0,1)$ and accepting if $r<\frac{\pi(x')}{\pi(x)}$, and otherwise rejecting. Furthermore, we don't just have a single Markov chain, but a collection of so-called ``walkers'', that each perform their own Markov chain. The integrand is then sampled at each position where the walkers reach.

One final note, is that since the current state of a Markov chain is dependent on the previous state, the Markov chain is not independent of itself. This is referred to as autocorrelation.\todo{cite} One method to reduce this autocorrelation and give essentially independent samples is known as blocking.\todo{cite}

\section{Variational (Quantum) Monte Carlo}
\label{sec:vmc}

As our first foray into \gls{QMC}, we consider \gls{VMC}. In section \ref{sec:variational_principle} we introduced the variational principle by parametrising the wave function and then finding the minimum of the expectation value of the energy occurring in the parametrisation space. If we have a large number of electrons and/or a large number of parameters, then the integrals involved in the evaluation of the energy will necessarily be high-dimensional. This is where \gls{MC} comes in. For basic trial wave functions and small atoms like Hydrogen or Helium, direct integration may be possible, but as discussed in the previous section, this quickly becomes impossible for larger systems.

For a trial wave function $\Psi$ (we omit the tilde from section \ref{sec:variational_principle}), the expectation value of the energy is
\begin{align}
    \label{eq:vmc_energy}
    \langle E \rangle &= \frac{\bra{\Psi}H\ket{\Psi}}{\bra{\Psi}\ket{\Psi}} \\
    &= \frac{\int\d^{3N}r\ \Psi^*H\Psi}{\int\d^{3N}r\ |\Psi|^2}.
\end{align}
We may calculate this integral using \gls{MC}, varying the parameters and stopping according to some minimisation algorithm. In particular, define the local energy as
\begin{equation}
    E_L(\bm r) = \frac{H\Psi}{\Psi}.
\end{equation}
Notice that the more strongly $\Psi$ resembles the exact wave function, the less strongly $E_L$ varies with $\bm r$. In particular, if $\Psi$ is equal to an exact eigenstate, then $E_L$ is constant. Therefore, an alternative objective function to the energy expectation of equation \ref{eq:vmc_energy} is the variance.\todo{cite}

Defining
\begin{equation}
    p(\bm r) = \frac{|\Psi|^2}{\int\d^{3N}r\ |\Psi|^2},
\end{equation}
we may write equation \ref{eq:vmc_energy} as
\begin{equation}
    \langle E\rangle = \frac{\int\d^{3N}r\ p(\bm r)E_L(\bm r)}{\int\d^{3N}r\ p(\bm r)}.
\end{equation}
However, $\int\d^{3N}r\ p(\bm r) = 1$ so
\begin{equation}
    \langle E\rangle = \int\d^{3N}r\ p(\bm r)E_L(\bm r).
\end{equation}

This form of the energy is amenable to the Metropolis-Hastings approach outlined in section \ref{sec:mcmc}. In principle, the algorithm is doable with just a single walker, but in practice we reduce the statistical error by using many. The algorithm then becomes

\begin{minipage}{\textwidth}
\begin{lstlisting}[escapeinside={(*}{*)}]
    Initialise (*$N$*) walkers in random positions.
    until convergence criterion met
      for each walker at position (*$r$*)
        sample the local energy (*$E_L$*) at (*$r$*)
        propose a new position (*$r'$*) with probably (*$p=|\Psi(r')/\Psi(r)|^2$ *)
        if (*$r'$*) is accepted
          set (*$r$*) to (*$r'$*)
\end{lstlisting}
\end{minipage}

The energy is then calculated as the expectation value of the local energy, averaged over the samples generated in this procedure. Steps at the beginning (before equilibrium) are discarded, and a blocking procedure should be employed. Decision to stop is generally based on compute time and/or precision required.


\subsection{Trial Wave Functions}
\label{sec:jastrow}

While \gls{VMC} is a powerful tool, the quality of the solution is constrained by the quality of the trial wave function. Moreover, the evluation of the trial wave function is expensive, and we therefore want a form that is easy to evaluate.

The form of the trial wave function is typically chosen based on a Jastrow factor, as already introduced in section \ref{sec:tc}. Generally,
\begin{equation}
    \Psi_\mathrm{trial} = \e^J\Phi.
\end{equation}

For computational efficiency, the Jastrow factor typically only retains one- and two-body terms,
\begin{equation}
    J = \sum_i \chi(\bm x_i) - \frac 12 \sum_{i\neq j} u(\bm x_i, \bm x_j),
\end{equation}
where $\chi$ describes electron-nuclear correlation and $u$ describes two-electron correlation. There exist a number of more specific forms for $J$\todo{citations}, though one unifying principle is for them to adhere to expected short-range (cusp conditions) and long-range ($1/r$) behaviour.

$\Phi$ is typically chosen to be a single Slater determinant.\todo{citations} In particular, by choosing the \gls{HF} determinant, typically only a small portion of the energy (that is, the correlation energy) is left for the Jastrow factor to describe, and typically even simple Jastrow factors can do this.\todo{cite: see Foulkes} However, sometimes this is not enough, for example, when the HF determinant is not sufficient to describe all symmetries of the true wave function.\todo{citations}

\section{Diffusion Monte Carlo}
\Gls{DMC} starts by performing a Wick rotation (that is, substitute $t\to i\tau$) in the time-dependent Schr\"odinger equation, equation \ref{eq:schrodinger}, we get the imaginary-time Schr\"odinger equation
\begin{equation}
    \label{eq:imag_time_schrodinger}
    \frac{\partial}{\partial\tau}\Psi(\bm r, \tau) = \hat H \Psi(\bm r, \tau)
\end{equation}
This equation is a diffusion (or heat) equation, and $\Psi$ may be interpreted as the density distribution for a large number of independent particles (walkers).\todo{citations} More specifically, the kinetic energy term, being second order, describes the movement of the particles whereas the potential energy term describes generation or annihilation of walkers. The solution of this equation is
\begin{equation}
    \Psi(\bm r, \tau) = \e^{(H-S)\tau}\Psi(\bm r, 0),
\end{equation}
where we have introduced the energy shift $S$ which is adapted to estimate the ground state energy.\todo{citations}

We may also express $\Psi$ in terms of its Green's function, in order to get a form that expresses a small time step,
\begin{equation}
\Psi(\bm r, \tau+\Delta\tau) = \int\d^{3N}r' \ G(\bm r, \bm r'; \Delta\tau),
\end{equation}
where the Green's function
\begin{equation}
G(\bm r, \bm r'; \Delta\tau) = \bra{r}\e^{-\Delta\tau(H-S)}\ket{r'}
\end{equation}
also obeys the imaginary-time Schr\"odinger equation, but with the initial condition
\begin{equation}
    G(\bm r, \bm r'; 0) = \delta(\bm r-\bm r').
\end{equation}

For small time steps, $G$ may be approximated by the Lie-Trotter-Suzuki decomposition,\todo{cite} i.e. for operators $A$, $A_k$,
\begin{equation}
    A = \sum_kA_k \implies \e^{-\alpha A} = \left( \prod_k e^{-\alpha A_k/M} \right)^M
\end{equation}
for some value $\alpha$ and for large $M$. From this, we can get the Green's function,
\begin{equation}
    G(\bm r, \bm r'; \Delta\tau) = \e^{-\Delta\tau(V(r)-S)}\frac{1}{\sqrt{2\pi\Delta\tau}}\e^{-(r - r')^2/(2\pi\Delta\tau)}+\mathcal{O}(\Delta\tau^2),
\end{equation}
which describes our time evolution.

In \gls{DMC}, walkers diffuse through configuration space in two stages: diffusion and branching. In the diffusion step, walkers are moved according to the kinetic terms in the Green's function. In the branching step, unfavourable walkers are removed and favourable ones produce new walkers.

For the energy shift estimate, we wish to choose a value such that the overall population does not change too much. If the walkers proliferate too much, then the computational cost becomes infeasible, whereas if too many walkers die, we are left with poor statistics. One way to choose $S$ is by keeping track of the population of walkers $M$ for a target populaton $M_\mathrm{target}$ and adjust,
\begin{equation}
    S = S_\mathrm{old} + \alpha\ln\left(\frac{M_\mathrm{target}}{M}\right)
\end{equation}
for small $\alpha$.

More concretely, in pseudocode, the basic \gls{DMC} algorithm is:

\begin{minipage}{\textwidth}
\begin{lstlisting}[escapeinside={(*}{*)}]
    Initialise (*$N$*) walkers in random positions.
    until convergence criterion met
        for each walker at position (*$r$*)
            shift position (*$\bm R$*) to (*$\bm R'$*) according to
                transition probability (*$G$*)
            evaluate (*$q=\e^{-\Delta\tau(V(\bm r')-S)}$*)
            walker survives with probability (*$q$*)
            if (*$q$*) is greater than 1
                create (*$1-q$*) new walkers
                    (with stochastic rounding)
        update (*$S$*).
\end{lstlisting}
\end{minipage}

Notice that in contrast to \gls{VMC}, \gls{DMC} does not rely on a variational principle, nor a trial wave function. There is also a discretisation error incurred by the operator decomposition, though this can be handled via an application of the Metropolis-Hastings alogirthm.\cite{thijssenComputational2007}
However, in practice a trial wave function is actually necessary for fermions, as we consider in electronic structure. The walker distribution is positive, but for fermions this is not the case due to their exchange statistics. In order to still practically use DMC, an approximation called the fixed node approximation is made, where the nodal structure (i.e. the roots of $\Psi$) of the distribution is determined by a trial function. Thus, the accuracy of DMC is still limited by the quality of the trial wave function (or more precisely, by its nodal surface).

% While \gls{DMC} does not rely on the variational principle, the convergence of its practical variants still relies on a trial wave function.


% \section{Auxiliary Field Quantum Monte Carlo}
% % may can skip AFQMC? Don't really see a point to including a full discussion of this method
% \section{The Fermion Sign Problem}
% \label{sec:sign_problem}
% \todo{make sure to mention the fixed node approximation here}
% maybe can also skip the fermion sign problem since it's not super relevant for me, just mention it vaguely in the DMC section

\section{Full Configuration Interaction Quantum Monte Carlo}
\label{sec:fciqmc}

The main post-Hartree-Fock method used throughout this dissertation is the \gls{FCIQMC} algorithm.\todo{citations} For this, there exist a few different implementations,\cite{Guther_neci_2020,spencerHANDEQMC2019b,brandRimujl2024,andersonRobertanderson2024} but we focus on \neci.\cite{Guther_neci_2020} As the name implies, \gls{FCIQMC} combines concepts from \gls{FCI} (discussed in section \ref{sec:ci}) and \gls{QMC} concepts already discussed in this chapter. In particular, it implements FCI, retaining many of its desirable properties such as size consistency and accuracy while being able to handle much larger systems thanks to its stochastic framework (however, the scaling remains expoential, like FCI). Like FCI, it is non-perturbative, and so can handle multi-reference problems, and unlike other QMC methods, it does not rely on a trial wave function. It can also be be used as a solver in place of FCI, like in a \gls{MCSCF} calculation.\todo{citations}

\subsection{Main Concepts}

\subsection{Energy Estimators}

\subsection{The Sign Problem in FCIQMC}

\subsection{The Initiator Approximation}

\subsection{Reduced Density Matrix Sampling}

\subsection{Combining TC with Modern Electronic Structure}
